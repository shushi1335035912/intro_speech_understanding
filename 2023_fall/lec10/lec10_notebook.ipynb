{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a424b44",
   "metadata": {},
   "source": [
    "# Speech Understanding \n",
    "# Lecture 10: Fourier analysis of natural speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3983e7c",
   "metadata": {},
   "source": [
    "### Mark Hasegawa-Johnson, KCGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa13a99",
   "metadata": {},
   "source": [
    "* A synthetic vowel can be analyzed by taking the Fourier transform of the whole numpy array\n",
    "* Real speech changes over time\n",
    "* In order to cope with the changes over time, we can use the short-time Fourier transform (STFT)\n",
    "* The log magnitude STFT is called the spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca0a6",
   "metadata": {},
   "source": [
    "Here are the contents:\n",
    "1. <a href=\"#section1\">Using ipywebrtc to record speech</a>\n",
    "1. <a href=\"#section2\">Using librosa to read speech audio files</a>\n",
    "1. <a href=\"#section3\">Calculating a spectrogram using `np.fft.fft`</a>\n",
    "1. <a href=\"#section4\">Calculating a spectrogram using librosa</a>\n",
    "1. <a href=\"#homework\">Homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5b87c",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1f1a1",
   "metadata": {},
   "source": [
    "## 1.  Using <a href=\"https://ipywebrtc.readthedocs.io/en/latest/\">ipywebrtc</a> to record speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958c9dc",
   "metadata": {},
   "source": [
    "[ipywebrtc](https://ipywebrtc.readthedocs.io/en/latest/) is a general package for recording audio and video into your Jupyter notebook.\n",
    "\n",
    "In order to use ipywebrtc, first you need to install it.  You can do that using the following shell command, or by issuing the same command without the \"!\" in a terminal window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e287d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywebrtc in c:\\users\\rog\\anaconda3\\lib\\site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywebrtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975c563",
   "metadata": {},
   "source": [
    "Recording audio using ipywebrtc is exactly the same as recording video, except that we create a `CameraStream` object with the constraints `'audio':True, 'video':False`.  With those constraints, the camera stream will record only audio, not video.\n",
    "\n",
    "When you the circle button is black, you can press it to start recording.  When it is red, you can press it to stop recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "005827bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11fea81566a44408dfe6020891440bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': â€¦"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywebrtc\n",
    "camera = ipywebrtc.CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = ipywebrtc.AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0382982",
   "metadata": {},
   "source": [
    "If we print the `recorder` object, we can see its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "487e353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': False}))\n"
     ]
    }
   ],
   "source": [
    "print(recorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddab695",
   "metadata": {},
   "source": [
    "We can see that it is an `AudioRecorder` object, with the following member data:\n",
    "* audio - an audio object, containing\n",
    "   * value - the binary data of the recorded audio waveform\n",
    "   * format='webm' - the audio coding format in which audio.value is stored\n",
    "* stream - the `CameraStream` object from which the audio was recorded\n",
    "\n",
    "There are several ways to convert the `audio.value` data into a numpy array, but one of the simplest and most general is to just save it as a binary `.webm` file, then read it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5835b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording.webm is a file containing 0 bytes\n"
     ]
    }
   ],
   "source": [
    "with open('recording.webm','wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "    \n",
    "import os\n",
    "print('recording.webm is a file containing',os.stat('recording.webm').st_size,'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a115a",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8148f",
   "metadata": {},
   "source": [
    "## 2. Using [librosa](https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html) to read speech audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c2dc3",
   "metadata": {},
   "source": [
    "[librosa](https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html) is a very general package for synthesizing and analyzing audio files.  For now, let's use it to read in the `.webm` file you just created.  First, you need to install it.  In this line, the `-q` flag prevents pip from printing anything unless there is an error.  If nothing is printed, then you have no errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe6fdb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c56b8",
   "metadata": {},
   "source": [
    "The [librosa.load](https://librosa.org/doc/latest/generated/librosa.load.html#librosa.load) function is able to read a wider variety of audio file formats than any other python package I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f30ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\AppData\\Local\\Temp\\ipykernel_31776\\223754044.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  speech, Fs = librosa.load('recording.webm',sr=16000)\n",
      "C:\\Users\\ROG\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'recording.webm': Format not recognised.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m speech, Fs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecording.webm\u001b[39m\u001b[38;5;124m'\u001b[39m,sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[0;32m      6\u001b[0m speech_time_axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(speech))\u001b[38;5;241m/\u001b[39mFs\n\u001b[0;32m      8\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m3\u001b[39m),layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\rawread.py:62\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m aifc\u001b[38;5;241m.\u001b[39mError:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Return to the beginning of the file to try the next reader.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    952\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Aifc_read(f)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Aifc_write(f)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\aifc.py:364\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# assume it is an open file object already\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitfp(f)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\aifc.py:320\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soundpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m file\n\u001b[1;32m--> 320\u001b[0m chunk \u001b[38;5;241m=\u001b[39m Chunk(file)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with FORM id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\chunk.py:67\u001b[0m, in \u001b[0;36mChunk.__init__\u001b[1;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkname \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkname) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack_from(strflag\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "speech, Fs = librosa.load('recording.webm',sr=16000)\n",
    "speech_time_axis = np.arange(len(speech))/Fs\n",
    "\n",
    "fig = plt.figure(figsize=(14,3),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.plot(speech_time_axis,speech)\n",
    "subplot.set_xlabel('Time (seconds)',fontsize=18)\n",
    "subplot.set_title('Recording sampled at %d samples/second'%(Fs),fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6953a",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea109e",
   "metadata": {},
   "source": [
    "## 3. Calculating a spectrogram using np.fft.fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b91f8c",
   "metadata": {},
   "source": [
    "* A Fourier transform finds out which tones are present in a sound\n",
    "* ... but speech changes over time!\n",
    "\n",
    "In order to solve this problem, we use the **short-time Fourier transform**, or STFT.  The STFT has two steps:\n",
    "\n",
    "1. Divide `speech` into overlapping frames, resulting in a matrix\n",
    "1. Take the Fourier transform of each frame to get the **STFT**\n",
    "1. The **spectrogram** is the log magnitude of the STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93215de8",
   "metadata": {},
   "source": [
    "### 3.1 Divide speech into overlapping frames\n",
    "\n",
    "Typically, we use frames that are about 0.025 seconds long (25 milliseconds), with a step of 0.01 seconds (10 milliseconds).\n",
    "\n",
    "There are an amazing number of different tricky ways to create overlapping frames in python; see [this page](https://stackoverflow.com/questions/2485669/consecutive-overlapping-subsets-of-array-numpy-python) for lots of methods.  The code below is intended to avoid tricky approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7885e134",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m frame_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.025\u001b[39m\u001b[38;5;241m*\u001b[39mFs)\n\u001b[0;32m      2\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.01\u001b[39m\u001b[38;5;241m*\u001b[39mFs)\n\u001b[0;32m      3\u001b[0m num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mlen\u001b[39m(speech)\u001b[38;5;241m-\u001b[39mframe_length)\u001b[38;5;241m/\u001b[39mstep)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Fs' is not defined"
     ]
    }
   ],
   "source": [
    "frame_length = int(0.025*Fs)\n",
    "step = int(0.01*Fs)\n",
    "num_frames = int((len(speech)-frame_length)/step)\n",
    "print('frame_length is',frame_length,'and step is',step,'and num_frames is',num_frames)\n",
    "\n",
    "speech_frames = np.zeros((frame_length, num_frames))\n",
    "for frame in range(num_frames):\n",
    "    speech_frames[:,frame] = speech[frame*step:frame*step+frame_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb940da8",
   "metadata": {},
   "source": [
    "We can plot this as an image.  Most of the samples will be near zero, and only a few will be strongly negative or strongly positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9cf5dcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m4\u001b[39m),layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m subplot \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m subplot\u001b[38;5;241m.\u001b[39mimshow(speech_frames,aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m subplot\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrame number\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m)\n\u001b[0;32m      5\u001b[0m subplot\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample number\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech_frames' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14,4),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.imshow(speech_frames,aspect='auto',origin='lower')\n",
    "subplot.set_xlabel('Frame number',fontsize=18)\n",
    "subplot.set_ylabel('Sample number',fontsize=18)\n",
    "subplot.set_title('Image of speech frames, 25ms frames with a 10ms step',fontsize=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976ef0e",
   "metadata": {},
   "source": [
    "### 3.2 Take the FFT of each frame to get the STFT\n",
    "\n",
    "The STFT is computed by taking the FFT of each frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c5183df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m speech_stft \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfft(speech_frames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m4\u001b[39m),layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m subplot \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech_frames' is not defined"
     ]
    }
   ],
   "source": [
    "speech_stft = np.fft.fft(speech_frames, axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(14,4),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.imshow(np.abs(speech_stft[:frame_length//2]),aspect='auto',origin='lower')\n",
    "subplot.set_xlabel('Frame number',fontsize=18)\n",
    "subplot.set_ylabel('Frequency bin',fontsize=18)\n",
    "subplot.set_title('Image of speech frames, 25ms frames with a 10ms step',fontsize=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea6c34",
   "metadata": {},
   "source": [
    "### 3.3 The spectrogram is the log magnitude STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd6ad8",
   "metadata": {},
   "source": [
    "As you can see from the plot above, the STFT is close to zero in most frequency bins.  Low-amplitude information can be made more visible by taking the logarithm.\n",
    "\n",
    "#### Standardization: Use decibels, `20*log10(abs(stft))`\n",
    "If you use `np.log` to calculate the logarithm, then your spectrogram units are not obvious.  If you use `20*np.log10`, then you can say that your spectrogram expresses levels in units of decibels.  The <a href=\"https://en.wikipedia.org/wiki/Decibel\">decibel</a> is an international standard way of expressing logarithms.  Since it's an international standard, it's nice to use it.\n",
    "\n",
    "#### Normalization: Normalize maximum to 0dB, Clip minimum to -60dB\n",
    "In order to avoid taking the logarithm of zero, it's a good idea to use `np.amax` and `np.maximum` so that the largest value is 0dB ($=20\\log_{10}(1)$), and the smallest value is -60dB ($=20\\log_{10}(0.001)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4118e3aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech_stft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mstft \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(speech_stft)\n\u001b[0;32m      2\u001b[0m speech_spectrogram \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0.001\u001b[39m,mstft\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mamax(mstft)))\n\u001b[0;32m      4\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m4\u001b[39m),layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech_stft' is not defined"
     ]
    }
   ],
   "source": [
    "mstft = np.abs(speech_stft)\n",
    "speech_spectrogram = 20*np.log10(np.maximum(0.001,mstft/np.amax(mstft)))\n",
    "                            \n",
    "fig = plt.figure(figsize=(14,4),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.imshow(speech_spectrogram[:frame_length//2],aspect='auto',origin='lower')\n",
    "subplot.set_xlabel('Frame number',fontsize=18)\n",
    "subplot.set_ylabel('Frequency bin',fontsize=18)\n",
    "subplot.set_title('Image of speech frames, 25ms frames with a 10ms step',fontsize=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564707ab",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606aa76c",
   "metadata": {},
   "source": [
    "## 4. Calculating a spectrogram using librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdf67d",
   "metadata": {},
   "source": [
    "librosa contains some useful functions:\n",
    "\n",
    "* <a href=\"https://librosa.org/doc/main/generated/librosa.stft.html\">librosa.stft</a> will chop a signal into frames, and find the STFT\n",
    "* <a href=\"https://librosa.org/doc/main/generated/librosa.amplitude_to_db.html\">librosa.amplitude_to_db</a> converts the magnitude to decibels\n",
    "* <a href=\"https://librosa.org/doc/main/generated/librosa.display.specshow.html#librosa.display.specshow\">librosa.display.specshow</a> has some extra settings that are useful for making useful images of spectrograms; for example, it can label the X-axis in seconds, and the Y-axis in Hertz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "add5997c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.01\u001b[39m\u001b[38;5;241m*\u001b[39mFs)\n\u001b[0;32m      4\u001b[0m framelength \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.025\u001b[39m\u001b[38;5;241m*\u001b[39mFs)\n\u001b[0;32m      6\u001b[0m librosa_stft \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mstft(speech,hop_length\u001b[38;5;241m=\u001b[39mstep,win_length\u001b[38;5;241m=\u001b[39mframelength)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Fs' is not defined"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "step = int(0.01*Fs)\n",
    "framelength = int(0.025*Fs)\n",
    "\n",
    "librosa_stft = librosa.stft(speech,hop_length=step,win_length=framelength)\n",
    "librosa_spectrogram = librosa.amplitude_to_db(np.abs(librosa_stft))\n",
    "librosa.display.specshow(librosa_spectrogram,sr=Fs,hop_length=step,x_axis='s',y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e813bc9",
   "metadata": {},
   "source": [
    "<a id=\"homework\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b32d4",
   "metadata": {},
   "source": [
    "## Homework "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eeaa5",
   "metadata": {},
   "source": [
    "Homework will be graded on Github.com.  Edit the file in this directory called `homework10.py`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751d6e2",
   "metadata": {},
   "source": [
    "### Homework 10.1: waveform_to_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8c8138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function waveform_to_frames in module homework10:\n",
      "\n",
      "waveform_to_frames(waveform, frame_length, step)\n",
      "    Chop a waveform into overlapping frames.\n",
      "    \n",
      "    @params:\n",
      "    waveform (np.ndarray(N)) - the waveform\n",
      "    frame_length (scalar) - length of the frame, in samples\n",
      "    step (scalar) - step size, in samples\n",
      "    \n",
      "    @returns:\n",
      "    frames (np.ndarray((frame_length, num_frames))) - waveform chopped into frames\n",
      "    \n",
      "    num_frames should be at least int((len(speech)-frame_length)/step); it may be longer.\n",
      "    For every n and t such that 0 <= t*step+n <= N-1, it should be the case that \n",
      "       frames[n,t] = waveform[t*step+n]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib, homework10\n",
    "importlib.reload(homework10)\n",
    "help(homework10.waveform_to_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "779f2d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(homework10)\n\u001b[1;32m----> 2\u001b[0m frames \u001b[38;5;241m=\u001b[39m homework10\u001b[38;5;241m.\u001b[39mwaveform_to_frames(speech, frame_length, step)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(frames,origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m,aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "frames = homework10.waveform_to_frames(speech, frame_length, step)\n",
    "plt.imshow(frames,origin='lower',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf95bf4",
   "metadata": {},
   "source": [
    "### Homework 10.2: frames_to_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06fa71a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function frames_to_stft in module homework10:\n",
      "\n",
      "frames_to_stft(frames)\n",
      "    Take the FFT of every column of the frames matrix.\n",
      "    \n",
      "    @params:\n",
      "    frames (np.ndarray((frame_length, num_frames))) - the speech samples (real-valued)\n",
      "    \n",
      "    @returns:\n",
      "    stft (np.ndarray((frame_length,num_frames))) - the STFT (complex-valued)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "help(homework10.frames_to_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63efbf9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(homework10)\n\u001b[1;32m----> 2\u001b[0m stft \u001b[38;5;241m=\u001b[39m homework10\u001b[38;5;241m.\u001b[39mframes_to_stft(frames)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mabs(stft[:frame_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]),origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m,aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "stft = homework10.frames_to_stft(frames)\n",
    "plt.imshow(np.abs(stft[:frame_length//2]),origin='lower',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb726db",
   "metadata": {},
   "source": [
    "### Homework 10.3: stft_to_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77121659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function stft_to_spectrogram in module homework10:\n",
      "\n",
      "stft_to_spectrogram(stft)\n",
      "    Calculate the level, in decibels, of each complex-valued sample of the STFT,\n",
      "    normalized so the highest value is 0dB, \n",
      "    and clipped so that the lowest value is -60dB.\n",
      "    \n",
      "    @params:\n",
      "    stft (np.ndarray((frame_length,num_frames))) - STFT (complex-valued)\n",
      "    \n",
      "    @returns:\n",
      "    spectrogram (np.ndarray((frame_length,num_frames)) - spectrogram (real-valued)\n",
      "    \n",
      "    The spectrogram should be expressed in decibels (20*log10(abs(stft)).\n",
      "    np.amax(spectrogram) should be 0dB.\n",
      "    np.amin(spectrogram) should be no smaller than -60dB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "help(homework10.stft_to_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86b2b544",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(homework10)\n\u001b[1;32m----> 2\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m homework10\u001b[38;5;241m.\u001b[39mstft_to_spectrogram(stft)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(spectrogram[:frame_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m],origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m,aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stft' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "spectrogram = homework10.stft_to_spectrogram(stft)\n",
    "plt.imshow(spectrogram[:frame_length//2],origin='lower',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dbe8c",
   "metadata": {},
   "source": [
    "### Receiving your grade\n",
    "\n",
    "In order to receive a grade for your homework, you need to:\n",
    "\n",
    "1. Run the following code block on your machine.  The result may list some errors, and then in the very last line, it will show a score.  That score (between 0% and 100%) is the grade you have earned so far.  If you want to earn a higher grade, please continue editing `homework3.py`, and then run this code block again.\n",
    "1. When you are happy with your score (e.g., when it reaches 100%), choose `File` $\\Rightarrow$ `Save and Checkpoint`.  Then use `GitHub Desktop` to commit and push your changes.\n",
    "1. Make sure that the 100% shows on your github repo on github.com.  If it doesn't, you will not receive credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98a99327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.008s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 successes out of 3 tests run\n",
      "Score: 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'grade' from 'C:\\\\Users\\\\ROG\\\\Documents\\\\GitHub\\\\intro_speech_understanding\\\\2023_fall\\\\lec10\\\\grade.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, grade\n",
    "importlib.reload(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
